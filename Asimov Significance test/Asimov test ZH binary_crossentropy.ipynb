{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First load os and sys so I can update the sys.path with new functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "change the luminosity to 80 /fb\n",
    "\n",
    "generate the 3 plots as in aewol paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take the paths to the functions we nedd\n",
    "module_path = os.path.abspath(os.path.join('./pandasPlotting/'))\n",
    "module2_path = os.path.abspath(os.path.join('./MlClasses/'))\n",
    "module3_path = os.path.abspath(os.path.join('./MlFunctions/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this part will include in the sys.path variables the paths for our new functions\n",
    "if [module_path, module2_path, module3_path] not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# here we are going to load what we will need, keras + tensorflow, plot functions, etc..\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "\n",
    "from keras import callbacks\n",
    "\n",
    "from pandasPlotting.Plotter import Plotter\n",
    "from pandasPlotting.dfFunctions import expandArrays\n",
    "from pandasPlotting.dtFunctions import featureImportance\n",
    "\n",
    "from MlClasses.MlData import MlData\n",
    "from MlClasses.Bdt import Bdt\n",
    "from MlClasses.Dnn import Dnn\n",
    "from MlClasses.ComparePerformances import ComparePerformances\n",
    "\n",
    "from MlFunctions.DnnFunctions import significanceLoss,significanceLossInvert,significanceLoss2Invert ,significanceLossInvertSqrt,significanceFull,asimovSignificanceLoss,asimovSignificanceLossInvert,asimovSignificanceFull,truePositive,falsePositive\n",
    "\n",
    "from linearAlgebraFunctions import gram,addGramToFlatDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I don't have patience to training 200 epochs ¯\\_(ツ)_/¯\n",
    "earlyStopping = callbacks.EarlyStopping(monitor='val_loss',min_delta=0,patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load our data files\n",
    "signal=pd.read_csv(\"../pyROOT_CPV_CPC/pp_wh/2dplots/analysis_with_cut/cpv_scan/charanjit_data/0L/feb/feb-0l-BSMlike/zh0p030lTCfeb.csv\",sep='\\s+',engine='python')\n",
    "bkgd=pd.read_csv(\"../pyROOT_CPV_CPC/pp_wh/2dplots/analysis_with_cut/cpv_scan/charanjit_data/0L/feb/feb-0l-BSMlike/zhsm0lTCfeb.csv\",sep='\\s+',engine='python')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine them into one dataset\n",
    "combined = pd.concat([signal,bkgd]).sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ptb1', 'ptb2', 'misset', 'pth', 'ptz', 'etah', 'phih', 'mtvh', 'ptvh',\n",
      "       'dphib1met', 'signal'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(combined.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change thes vars depend on which dataset you are loading, I will implement a better solution.\n",
    "chosenVars = {\n",
    "            # #A vanilla analysis with HL variables and lead 3 jets\n",
    "            '0L':['ptb1', 'ptb2', 'misset', 'pth', 'ptz', 'etah', 'phih', 'mtvh', 'ptvh', 'dphib1met', 'signal'],\n",
    "            #'2L':['ptb1', 'ptb2', 'ptl1', 'ptl2', 'pth', 'ptz', 'etah', 'phih',\n",
    "            #     'deltarll', 'deltarbl', 'mtvh', 'ptvh', 'dphil1b1', 'dphil1b2', 'signal']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainedModels={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#needed to plot asimov significane\n",
    "asimovSigLossSysts=[0.01,0.05,0.1,0.2,0.3,0.4,0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here I have included one archtecture I got from my ES scan, pls comment my entry and use dnn_batch4096 instead.\n",
    "dnnConfigs={\n",
    "    #'dnn_ZH_0L_cHW_0d001_batch_1024':{'epochs':200,'batch_size':1024,'dropOut':0.2,'l2Regularization':None,'hiddenLayers':[1.0],\n",
    "    #             'optimizer':'adam', 'activation':'relu'}\n",
    "    #'dnn_ZH_0L_cHW_0d01_batch_1024':{'epochs':200,'batch_size':1024,'dropOut':0.2,'l2Regularization':None,'hiddenLayers':[1.0],\n",
    "    #             'optimizer':'adam', 'activation':'relu'}\n",
    "    'dnn_ZH_0L_cHW_0d03_batch_1024':{'epochs':200,'batch_size':1024,'dropOut':0.2,'l2Regularization':None,'hiddenLayers':[1.0],\n",
    "                 'optimizer':'adam', 'activation':'relu'}\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bsmlike signal cHW 0.03: 11.867fb, bg:0.89\n",
    "#inclusive signal cHW 0.001: 2.198fb, bg:2.03fb\n",
    "#inclusive signal cHW 0.01: 4.553fb, bg:2.03fb\n",
    "#inclusive signal cHW 0.03: 14fb, bg:2.03fb\n",
    "\n",
    "lumi=80. #luminosity in /fb\n",
    "expectedSignal=11.867*lumi \n",
    "expectedBkgd=0.89*lumi #cross section of ttbar sample in fb times efficiency measured by Marco\n",
    "systematic=0.5 #systematic for the asimov signficance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felipe/hepML/MlClasses/Dnn.py:101: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  self.history = self.model.fit(self.data.X_train.as_matrix(), self.data.y_train.as_matrix(), sample_weight=self.data.weights_train,\n",
      "/home/felipe/hepML/MlClasses/Dnn.py:102: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  validation_data=(self.data.X_test.as_matrix(),self.data.y_test.as_matrix(),self.data.weights_test),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 140000 samples, validate on 60000 samples\n",
      "Epoch 1/200\n",
      "140000/140000 [==============================] - 1s 7us/step - loss: 0.6501 - acc: 0.6162 - sigLoss: -486.6820 - significance: 22.9101 - asimovSignificance: 12.3342 - truePositive: 0.5790 - falsePositive: 0.3464 - val_loss: 0.5659 - val_acc: 0.7149 - val_sigLoss: -547.5568 - val_significance: 23.7150 - val_asimovSignificance: 17.0205 - val_truePositive: 0.6055 - val_falsePositive: 0.1765\n",
      "Epoch 2/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5602 - acc: 0.7084 - sigLoss: -557.3877 - significance: 23.7617 - asimovSignificance: 16.4277 - truePositive: 0.6090 - falsePositive: 0.1917 - val_loss: 0.5413 - val_acc: 0.7278 - val_sigLoss: -572.5714 - val_significance: 23.5164 - val_asimovSignificance: 18.8226 - val_truePositive: 0.5929 - val_falsePositive: 0.1385\n",
      "Epoch 3/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5486 - acc: 0.7182 - sigLoss: -571.1858 - significance: 23.6575 - asimovSignificance: 17.5156 - truePositive: 0.6018 - falsePositive: 0.1651 - val_loss: 0.5355 - val_acc: 0.7289 - val_sigLoss: -577.5331 - val_significance: 23.4368 - val_asimovSignificance: 19.1681 - val_truePositive: 0.5885 - val_falsePositive: 0.1320\n",
      "Epoch 4/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5458 - acc: 0.7230 - sigLoss: -573.9544 - significance: 23.5694 - asimovSignificance: 18.2100 - truePositive: 0.5964 - falsePositive: 0.1500 - val_loss: 0.5335 - val_acc: 0.7307 - val_sigLoss: -581.4358 - val_significance: 23.5855 - val_asimovSignificance: 19.0486 - val_truePositive: 0.5961 - val_falsePositive: 0.1359\n",
      "Epoch 5/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5427 - acc: 0.7254 - sigLoss: -576.0057 - significance: 23.6595 - asimovSignificance: 18.3148 - truePositive: 0.6008 - falsePositive: 0.1497 - val_loss: 0.5317 - val_acc: 0.7323 - val_sigLoss: -582.0943 - val_significance: 23.7072 - val_asimovSignificance: 18.9612 - val_truePositive: 0.6024 - val_falsePositive: 0.1390\n",
      "Epoch 6/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5415 - acc: 0.7279 - sigLoss: -577.2070 - significance: 23.7789 - asimovSignificance: 18.3444 - truePositive: 0.6069 - falsePositive: 0.1507 - val_loss: 0.5306 - val_acc: 0.7328 - val_sigLoss: -583.0876 - val_significance: 23.8183 - val_asimovSignificance: 18.7695 - val_truePositive: 0.6083 - val_falsePositive: 0.1438\n",
      "Epoch 7/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5402 - acc: 0.7287 - sigLoss: -577.6518 - significance: 23.8522 - asimovSignificance: 18.2857 - truePositive: 0.6108 - falsePositive: 0.1529 - val_loss: 0.5299 - val_acc: 0.7336 - val_sigLoss: -585.4652 - val_significance: 23.9720 - val_asimovSignificance: 18.5248 - val_truePositive: 0.6165 - val_falsePositive: 0.1503\n",
      "Epoch 8/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5395 - acc: 0.7300 - sigLoss: -579.1571 - significance: 23.9725 - asimovSignificance: 18.1701 - truePositive: 0.6170 - falsePositive: 0.1565 - val_loss: 0.5293 - val_acc: 0.7337 - val_sigLoss: -582.8209 - val_significance: 23.9721 - val_asimovSignificance: 18.5321 - val_truePositive: 0.6165 - val_falsePositive: 0.1502\n",
      "Epoch 9/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5389 - acc: 0.7302 - sigLoss: -578.1881 - significance: 23.9887 - asimovSignificance: 18.1665 - truePositive: 0.6179 - falsePositive: 0.1570 - val_loss: 0.5289 - val_acc: 0.7339 - val_sigLoss: -583.4286 - val_significance: 24.0266 - val_asimovSignificance: 18.4372 - val_truePositive: 0.6195 - val_falsePositive: 0.1527\n",
      "Epoch 10/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5383 - acc: 0.7307 - sigLoss: -579.5151 - significance: 24.0726 - asimovSignificance: 18.0597 - truePositive: 0.6224 - falsePositive: 0.1607 - val_loss: 0.5286 - val_acc: 0.7340 - val_sigLoss: -582.3929 - val_significance: 24.0491 - val_asimovSignificance: 18.3986 - val_truePositive: 0.6207 - val_falsePositive: 0.1537\n",
      "Epoch 11/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5377 - acc: 0.7308 - sigLoss: -579.6198 - significance: 24.0788 - asimovSignificance: 18.0507 - truePositive: 0.6227 - falsePositive: 0.1608 - val_loss: 0.5285 - val_acc: 0.7342 - val_sigLoss: -582.8835 - val_significance: 24.0892 - val_asimovSignificance: 18.3438 - val_truePositive: 0.6228 - val_falsePositive: 0.1553\n",
      "Epoch 12/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5379 - acc: 0.7308 - sigLoss: -579.1278 - significance: 24.1120 - asimovSignificance: 17.9805 - truePositive: 0.6246 - falsePositive: 0.1626 - val_loss: 0.5284 - val_acc: 0.7346 - val_sigLoss: -586.5926 - val_significance: 24.2082 - val_asimovSignificance: 18.1387 - val_truePositive: 0.6293 - val_falsePositive: 0.1610\n",
      "Epoch 13/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5371 - acc: 0.7313 - sigLoss: -579.9894 - significance: 24.1387 - asimovSignificance: 17.9889 - truePositive: 0.6259 - falsePositive: 0.1629 - val_loss: 0.5286 - val_acc: 0.7350 - val_sigLoss: -587.5093 - val_significance: 24.2651 - val_asimovSignificance: 18.0629 - val_truePositive: 0.6324 - val_falsePositive: 0.1632\n",
      "Epoch 14/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5370 - acc: 0.7311 - sigLoss: -580.4627 - significance: 24.1586 - asimovSignificance: 17.9238 - truePositive: 0.6271 - falsePositive: 0.1645 - val_loss: 0.5282 - val_acc: 0.7349 - val_sigLoss: -584.7371 - val_significance: 24.2045 - val_asimovSignificance: 18.1741 - val_truePositive: 0.6291 - val_falsePositive: 0.1602\n",
      "Epoch 15/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5367 - acc: 0.7319 - sigLoss: -580.5144 - significance: 24.2107 - asimovSignificance: 17.9101 - truePositive: 0.6298 - falsePositive: 0.1657 - val_loss: 0.5283 - val_acc: 0.7350 - val_sigLoss: -586.5009 - val_significance: 24.2987 - val_asimovSignificance: 17.9997 - val_truePositive: 0.6342 - val_falsePositive: 0.1650\n",
      "Epoch 16/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5367 - acc: 0.7315 - sigLoss: -580.2058 - significance: 24.2346 - asimovSignificance: 17.8103 - truePositive: 0.6311 - falsePositive: 0.1678 - val_loss: 0.5283 - val_acc: 0.7349 - val_sigLoss: -587.6909 - val_significance: 24.3282 - val_asimovSignificance: 17.9363 - val_truePositive: 0.6359 - val_falsePositive: 0.1668\n",
      "Epoch 17/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5368 - acc: 0.7318 - sigLoss: -581.3852 - significance: 24.2677 - asimovSignificance: 17.7895 - truePositive: 0.6330 - falsePositive: 0.1690 - val_loss: 0.5282 - val_acc: 0.7344 - val_sigLoss: -584.0903 - val_significance: 24.2765 - val_asimovSignificance: 17.9841 - val_truePositive: 0.6331 - val_falsePositive: 0.1651\n",
      "Epoch 18/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5363 - acc: 0.7319 - sigLoss: -580.1530 - significance: 24.2741 - asimovSignificance: 17.7960 - truePositive: 0.6333 - falsePositive: 0.1690 - val_loss: 0.5283 - val_acc: 0.7347 - val_sigLoss: -587.7509 - val_significance: 24.3657 - val_asimovSignificance: 17.8432 - val_truePositive: 0.6380 - val_falsePositive: 0.1693\n",
      "Epoch 19/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5364 - acc: 0.7320 - sigLoss: -580.9897 - significance: 24.2813 - asimovSignificance: 17.7846 - truePositive: 0.6336 - falsePositive: 0.1692 - val_loss: 0.5283 - val_acc: 0.7348 - val_sigLoss: -585.9765 - val_significance: 24.3901 - val_asimovSignificance: 17.8056 - val_truePositive: 0.6393 - val_falsePositive: 0.1704\n",
      "Epoch 20/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5362 - acc: 0.7315 - sigLoss: -581.2960 - significance: 24.3193 - asimovSignificance: 17.6572 - truePositive: 0.6359 - falsePositive: 0.1725 - val_loss: 0.5281 - val_acc: 0.7350 - val_sigLoss: -584.5481 - val_significance: 24.3737 - val_asimovSignificance: 17.8562 - val_truePositive: 0.6384 - val_falsePositive: 0.1692\n",
      "Epoch 21/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5367 - acc: 0.7321 - sigLoss: -580.1097 - significance: 24.3128 - asimovSignificance: 17.7367 - truePositive: 0.6354 - falsePositive: 0.1708 - val_loss: 0.5283 - val_acc: 0.7350 - val_sigLoss: -586.3993 - val_significance: 24.3969 - val_asimovSignificance: 17.8110 - val_truePositive: 0.6396 - val_falsePositive: 0.1705\n",
      "Epoch 22/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5360 - acc: 0.7315 - sigLoss: -580.9814 - significance: 24.3151 - asimovSignificance: 17.6658 - truePositive: 0.6357 - falsePositive: 0.1724 - val_loss: 0.5279 - val_acc: 0.7349 - val_sigLoss: -584.8794 - val_significance: 24.3404 - val_asimovSignificance: 17.9122 - val_truePositive: 0.6365 - val_falsePositive: 0.1675\n",
      "Epoch 23/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5355 - acc: 0.7318 - sigLoss: -581.7597 - significance: 24.3565 - asimovSignificance: 17.6226 - truePositive: 0.6378 - falsePositive: 0.1739 - val_loss: 0.5280 - val_acc: 0.7349 - val_sigLoss: -585.7959 - val_significance: 24.4213 - val_asimovSignificance: 17.7490 - val_truePositive: 0.6410 - val_falsePositive: 0.1721\n",
      "Epoch 24/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5360 - acc: 0.7319 - sigLoss: -580.4797 - significance: 24.3493 - asimovSignificance: 17.6469 - truePositive: 0.6374 - falsePositive: 0.1733 - val_loss: 0.5281 - val_acc: 0.7348 - val_sigLoss: -586.8561 - val_significance: 24.4392 - val_asimovSignificance: 17.7139 - val_truePositive: 0.6420 - val_falsePositive: 0.1732\n",
      "Epoch 25/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5363 - acc: 0.7322 - sigLoss: -580.4722 - significance: 24.3497 - asimovSignificance: 17.6788 - truePositive: 0.6374 - falsePositive: 0.1727 - val_loss: 0.5281 - val_acc: 0.7347 - val_sigLoss: -589.0273 - val_significance: 24.4785 - val_asimovSignificance: 17.6249 - val_truePositive: 0.6442 - val_falsePositive: 0.1757\n",
      "Epoch 26/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5362 - acc: 0.7316 - sigLoss: -581.7517 - significance: 24.3841 - asimovSignificance: 17.5567 - truePositive: 0.6394 - falsePositive: 0.1756 - val_loss: 0.5281 - val_acc: 0.7350 - val_sigLoss: -583.8174 - val_significance: 24.3942 - val_asimovSignificance: 17.8144 - val_truePositive: 0.6395 - val_falsePositive: 0.1703\n",
      "Epoch 27/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5359 - acc: 0.7316 - sigLoss: -580.5143 - significance: 24.3545 - asimovSignificance: 17.6136 - truePositive: 0.6378 - falsePositive: 0.1742 - val_loss: 0.5282 - val_acc: 0.7346 - val_sigLoss: -586.9383 - val_significance: 24.4684 - val_asimovSignificance: 17.6393 - val_truePositive: 0.6437 - val_falsePositive: 0.1752\n",
      "Epoch 28/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5359 - acc: 0.7319 - sigLoss: -581.2530 - significance: 24.3837 - asimovSignificance: 17.5798 - truePositive: 0.6393 - falsePositive: 0.1751 - val_loss: 0.5284 - val_acc: 0.7349 - val_sigLoss: -586.7477 - val_significance: 24.4959 - val_asimovSignificance: 17.6099 - val_truePositive: 0.6452 - val_falsePositive: 0.1763\n",
      "Epoch 29/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5361 - acc: 0.7314 - sigLoss: -580.7758 - significance: 24.3548 - asimovSignificance: 17.5890 - truePositive: 0.6377 - falsePositive: 0.1745 - val_loss: 0.5281 - val_acc: 0.7348 - val_sigLoss: -585.6391 - val_significance: 24.4393 - val_asimovSignificance: 17.7149 - val_truePositive: 0.6420 - val_falsePositive: 0.1732\n",
      "Epoch 30/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5358 - acc: 0.7315 - sigLoss: -580.8861 - significance: 24.3426 - asimovSignificance: 17.6095 - truePositive: 0.6371 - falsePositive: 0.1739 - val_loss: 0.5280 - val_acc: 0.7348 - val_sigLoss: -583.4197 - val_significance: 24.4039 - val_asimovSignificance: 17.7708 - val_truePositive: 0.6401 - val_falsePositive: 0.1714\n",
      "Epoch 31/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5359 - acc: 0.7319 - sigLoss: -580.1089 - significance: 24.3621 - asimovSignificance: 17.6245 - truePositive: 0.6382 - falsePositive: 0.1740 - val_loss: 0.5282 - val_acc: 0.7349 - val_sigLoss: -589.5889 - val_significance: 24.5376 - val_asimovSignificance: 17.5394 - val_truePositive: 0.6475 - val_falsePositive: 0.1785\n",
      "Epoch 32/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5359 - acc: 0.7315 - sigLoss: -581.4316 - significance: 24.4079 - asimovSignificance: 17.4995 - truePositive: 0.6407 - falsePositive: 0.1773 - val_loss: 0.5281 - val_acc: 0.7345 - val_sigLoss: -585.6213 - val_significance: 24.4463 - val_asimovSignificance: 17.6716 - val_truePositive: 0.6425 - val_falsePositive: 0.1742\n",
      "Epoch 33/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5358 - acc: 0.7319 - sigLoss: -580.5467 - significance: 24.3896 - asimovSignificance: 17.5707 - truePositive: 0.6397 - falsePositive: 0.1755 - val_loss: 0.5281 - val_acc: 0.7345 - val_sigLoss: -586.6373 - val_significance: 24.4865 - val_asimovSignificance: 17.5961 - val_truePositive: 0.6447 - val_falsePositive: 0.1764\n",
      "Epoch 34/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5356 - acc: 0.7318 - sigLoss: -580.8402 - significance: 24.3755 - asimovSignificance: 17.5941 - truePositive: 0.6389 - falsePositive: 0.1750 - val_loss: 0.5281 - val_acc: 0.7347 - val_sigLoss: -586.1380 - val_significance: 24.4415 - val_asimovSignificance: 17.6973 - val_truePositive: 0.6422 - val_falsePositive: 0.1735\n",
      "Epoch 35/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5354 - acc: 0.7313 - sigLoss: -581.0327 - significance: 24.3318 - asimovSignificance: 17.6248 - truePositive: 0.6366 - falsePositive: 0.1736 - val_loss: 0.5280 - val_acc: 0.7348 - val_sigLoss: -587.4006 - val_significance: 24.5310 - val_asimovSignificance: 17.5386 - val_truePositive: 0.6471 - val_falsePositive: 0.1784\n",
      "Epoch 36/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5354 - acc: 0.7315 - sigLoss: -580.9706 - significance: 24.3981 - asimovSignificance: 17.5250 - truePositive: 0.6402 - falsePositive: 0.1768 - val_loss: 0.5281 - val_acc: 0.7347 - val_sigLoss: -585.9517 - val_significance: 24.4132 - val_asimovSignificance: 17.7494 - val_truePositive: 0.6406 - val_falsePositive: 0.1720\n",
      "Epoch 37/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5353 - acc: 0.7317 - sigLoss: -580.8502 - significance: 24.3502 - asimovSignificance: 17.6305 - truePositive: 0.6375 - falsePositive: 0.1737 - val_loss: 0.5280 - val_acc: 0.7347 - val_sigLoss: -584.2850 - val_significance: 24.4595 - val_asimovSignificance: 17.6632 - val_truePositive: 0.6432 - val_falsePositive: 0.1746\n",
      "Epoch 38/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5355 - acc: 0.7317 - sigLoss: -580.6675 - significance: 24.3510 - asimovSignificance: 17.6154 - truePositive: 0.6376 - falsePositive: 0.1739 - val_loss: 0.5282 - val_acc: 0.7343 - val_sigLoss: -586.3368 - val_significance: 24.4957 - val_asimovSignificance: 17.5623 - val_truePositive: 0.6452 - val_falsePositive: 0.1774\n",
      "Epoch 39/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5355 - acc: 0.7315 - sigLoss: -580.6562 - significance: 24.3702 - asimovSignificance: 17.5652 - truePositive: 0.6386 - falsePositive: 0.1753 - val_loss: 0.5279 - val_acc: 0.7349 - val_sigLoss: -585.4739 - val_significance: 24.4842 - val_asimovSignificance: 17.6388 - val_truePositive: 0.6445 - val_falsePositive: 0.1755\n",
      "Epoch 40/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5355 - acc: 0.7319 - sigLoss: -580.8345 - significance: 24.3919 - asimovSignificance: 17.5789 - truePositive: 0.6398 - falsePositive: 0.1755 - val_loss: 0.5279 - val_acc: 0.7347 - val_sigLoss: -586.7906 - val_significance: 24.4528 - val_asimovSignificance: 17.6758 - val_truePositive: 0.6428 - val_falsePositive: 0.1741\n",
      "Epoch 41/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5359 - acc: 0.7316 - sigLoss: -580.2096 - significance: 24.3467 - asimovSignificance: 17.6214 - truePositive: 0.6373 - falsePositive: 0.1737 - val_loss: 0.5278 - val_acc: 0.7348 - val_sigLoss: -584.1788 - val_significance: 24.4581 - val_asimovSignificance: 17.6706 - val_truePositive: 0.6431 - val_falsePositive: 0.1744\n",
      "Epoch 42/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5354 - acc: 0.7314 - sigLoss: -580.6136 - significance: 24.3838 - asimovSignificance: 17.5268 - truePositive: 0.6394 - falsePositive: 0.1764 - val_loss: 0.5280 - val_acc: 0.7346 - val_sigLoss: -584.6838 - val_significance: 24.4439 - val_asimovSignificance: 17.6760 - val_truePositive: 0.6423 - val_falsePositive: 0.1740\n",
      "Epoch 43/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5354 - acc: 0.7315 - sigLoss: -580.7045 - significance: 24.3568 - asimovSignificance: 17.5776 - truePositive: 0.6380 - falsePositive: 0.1748 - val_loss: 0.5278 - val_acc: 0.7348 - val_sigLoss: -584.4915 - val_significance: 24.4376 - val_asimovSignificance: 17.7142 - val_truePositive: 0.6419 - val_falsePositive: 0.1731\n",
      "Epoch 44/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5354 - acc: 0.7319 - sigLoss: -580.4558 - significance: 24.3779 - asimovSignificance: 17.5878 - truePositive: 0.6390 - falsePositive: 0.1751 - val_loss: 0.5278 - val_acc: 0.7346 - val_sigLoss: -585.2873 - val_significance: 24.4523 - val_asimovSignificance: 17.6608 - val_truePositive: 0.6428 - val_falsePositive: 0.1745\n",
      "Epoch 45/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5353 - acc: 0.7317 - sigLoss: -580.3033 - significance: 24.3368 - asimovSignificance: 17.6464 - truePositive: 0.6368 - falsePositive: 0.1730 - val_loss: 0.5279 - val_acc: 0.7350 - val_sigLoss: -587.5991 - val_significance: 24.5166 - val_asimovSignificance: 17.5896 - val_truePositive: 0.6463 - val_falsePositive: 0.1771\n",
      "Epoch 46/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5353 - acc: 0.7319 - sigLoss: -581.0056 - significance: 24.3914 - asimovSignificance: 17.5723 - truePositive: 0.6397 - falsePositive: 0.1756 - val_loss: 0.5280 - val_acc: 0.7345 - val_sigLoss: -586.3747 - val_significance: 24.4621 - val_asimovSignificance: 17.6366 - val_truePositive: 0.6433 - val_falsePositive: 0.1752\n",
      "Epoch 47/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5356 - acc: 0.7317 - sigLoss: -580.1272 - significance: 24.3650 - asimovSignificance: 17.5871 - truePositive: 0.6383 - falsePositive: 0.1747 - val_loss: 0.5280 - val_acc: 0.7350 - val_sigLoss: -588.1758 - val_significance: 24.5169 - val_asimovSignificance: 17.5857 - val_truePositive: 0.6463 - val_falsePositive: 0.1771\n",
      "Epoch 48/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5353 - acc: 0.7317 - sigLoss: -581.9365 - significance: 24.4194 - asimovSignificance: 17.4952 - truePositive: 0.6414 - falsePositive: 0.1776 - val_loss: 0.5280 - val_acc: 0.7347 - val_sigLoss: -583.4855 - val_significance: 24.4122 - val_asimovSignificance: 17.7540 - val_truePositive: 0.6405 - val_falsePositive: 0.1719\n",
      "Epoch 49/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5353 - acc: 0.7321 - sigLoss: -579.9291 - significance: 24.3545 - asimovSignificance: 17.6575 - truePositive: 0.6377 - falsePositive: 0.1731 - val_loss: 0.5279 - val_acc: 0.7350 - val_sigLoss: -585.4511 - val_significance: 24.4928 - val_asimovSignificance: 17.6267 - val_truePositive: 0.6450 - val_falsePositive: 0.1758\n",
      "Epoch 50/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5354 - acc: 0.7317 - sigLoss: -580.7735 - significance: 24.3725 - asimovSignificance: 17.5765 - truePositive: 0.6388 - falsePositive: 0.1751 - val_loss: 0.5281 - val_acc: 0.7348 - val_sigLoss: -586.0302 - val_significance: 24.4435 - val_asimovSignificance: 17.7056 - val_truePositive: 0.6423 - val_falsePositive: 0.1734\n",
      "Epoch 51/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5356 - acc: 0.7314 - sigLoss: -580.8855 - significance: 24.3588 - asimovSignificance: 17.5938 - truePositive: 0.6380 - falsePositive: 0.1748 - val_loss: 0.5281 - val_acc: 0.7352 - val_sigLoss: -587.5865 - val_significance: 24.5044 - val_asimovSignificance: 17.6284 - val_truePositive: 0.6456 - val_falsePositive: 0.1761\n",
      "Epoch 52/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5353 - acc: 0.7314 - sigLoss: -580.0552 - significance: 24.3755 - asimovSignificance: 17.5594 - truePositive: 0.6390 - falsePositive: 0.1759 - val_loss: 0.5278 - val_acc: 0.7345 - val_sigLoss: -585.0771 - val_significance: 24.4150 - val_asimovSignificance: 17.7249 - val_truePositive: 0.6407 - val_falsePositive: 0.1726\n",
      "Epoch 53/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5356 - acc: 0.7316 - sigLoss: -580.7675 - significance: 24.3519 - asimovSignificance: 17.6023 - truePositive: 0.6377 - falsePositive: 0.1743 - val_loss: 0.5279 - val_acc: 0.7348 - val_sigLoss: -583.7680 - val_significance: 24.4548 - val_asimovSignificance: 17.6801 - val_truePositive: 0.6429 - val_falsePositive: 0.1741\n",
      "Epoch 54/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5352 - acc: 0.7317 - sigLoss: -580.5351 - significance: 24.3947 - asimovSignificance: 17.5418 - truePositive: 0.6400 - falsePositive: 0.1761 - val_loss: 0.5279 - val_acc: 0.7348 - val_sigLoss: -582.1951 - val_significance: 24.3921 - val_asimovSignificance: 17.8019 - val_truePositive: 0.6394 - val_falsePositive: 0.1706\n",
      "Epoch 55/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5357 - acc: 0.7320 - sigLoss: -579.9210 - significance: 24.3657 - asimovSignificance: 17.6300 - truePositive: 0.6383 - falsePositive: 0.1740 - val_loss: 0.5283 - val_acc: 0.7347 - val_sigLoss: -590.6136 - val_significance: 24.6091 - val_asimovSignificance: 17.4031 - val_truePositive: 0.6515 - val_falsePositive: 0.1828\n",
      "Epoch 56/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5352 - acc: 0.7315 - sigLoss: -581.1501 - significance: 24.3737 - asimovSignificance: 17.5555 - truePositive: 0.6388 - falsePositive: 0.1757 - val_loss: 0.5281 - val_acc: 0.7349 - val_sigLoss: -588.2885 - val_significance: 24.5556 - val_asimovSignificance: 17.5108 - val_truePositive: 0.6485 - val_falsePositive: 0.1795\n",
      "Epoch 57/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5352 - acc: 0.7319 - sigLoss: -580.8328 - significance: 24.3828 - asimovSignificance: 17.5761 - truePositive: 0.6393 - falsePositive: 0.1753 - val_loss: 0.5280 - val_acc: 0.7348 - val_sigLoss: -584.6389 - val_significance: 24.5147 - val_asimovSignificance: 17.5758 - val_truePositive: 0.6462 - val_falsePositive: 0.1773\n",
      "Epoch 58/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5349 - acc: 0.7319 - sigLoss: -580.5831 - significance: 24.4026 - asimovSignificance: 17.5503 - truePositive: 0.6403 - falsePositive: 0.1762 - val_loss: 0.5279 - val_acc: 0.7347 - val_sigLoss: -587.7361 - val_significance: 24.5683 - val_asimovSignificance: 17.4719 - val_truePositive: 0.6492 - val_falsePositive: 0.1805\n",
      "Epoch 59/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5353 - acc: 0.7320 - sigLoss: -580.8793 - significance: 24.3851 - asimovSignificance: 17.5872 - truePositive: 0.6394 - falsePositive: 0.1753 - val_loss: 0.5279 - val_acc: 0.7352 - val_sigLoss: -586.4156 - val_significance: 24.5262 - val_asimovSignificance: 17.5902 - val_truePositive: 0.6468 - val_falsePositive: 0.1772\n",
      "Epoch 60/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5357 - acc: 0.7320 - sigLoss: -580.7842 - significance: 24.4079 - asimovSignificance: 17.5454 - truePositive: 0.6406 - falsePositive: 0.1764 - val_loss: 0.5279 - val_acc: 0.7350 - val_sigLoss: -584.6763 - val_significance: 24.4904 - val_asimovSignificance: 17.6321 - val_truePositive: 0.6448 - val_falsePositive: 0.1757\n",
      "Epoch 61/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5355 - acc: 0.7317 - sigLoss: -580.7667 - significance: 24.3976 - asimovSignificance: 17.5357 - truePositive: 0.6401 - falsePositive: 0.1764 - val_loss: 0.5280 - val_acc: 0.7350 - val_sigLoss: -583.1169 - val_significance: 24.4951 - val_asimovSignificance: 17.6260 - val_truePositive: 0.6451 - val_falsePositive: 0.1759\n",
      "Epoch 62/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5354 - acc: 0.7318 - sigLoss: -580.3043 - significance: 24.3686 - asimovSignificance: 17.6021 - truePositive: 0.6385 - falsePositive: 0.1744 - val_loss: 0.5280 - val_acc: 0.7351 - val_sigLoss: -582.1262 - val_significance: 24.4834 - val_asimovSignificance: 17.6637 - val_truePositive: 0.6444 - val_falsePositive: 0.1750\n",
      "Epoch 63/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5356 - acc: 0.7322 - sigLoss: -580.4675 - significance: 24.3916 - asimovSignificance: 17.5947 - truePositive: 0.6397 - falsePositive: 0.1751 - val_loss: 0.5279 - val_acc: 0.7344 - val_sigLoss: -586.2425 - val_significance: 24.4406 - val_asimovSignificance: 17.6660 - val_truePositive: 0.6422 - val_falsePositive: 0.1742\n",
      "Epoch 64/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5353 - acc: 0.7316 - sigLoss: -581.0654 - significance: 24.3867 - asimovSignificance: 17.5537 - truePositive: 0.6396 - falsePositive: 0.1760 - val_loss: 0.5279 - val_acc: 0.7349 - val_sigLoss: -583.7332 - val_significance: 24.4444 - val_asimovSignificance: 17.7085 - val_truePositive: 0.6423 - val_falsePositive: 0.1733\n",
      "Epoch 65/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5354 - acc: 0.7315 - sigLoss: -579.8075 - significance: 24.3592 - asimovSignificance: 17.5955 - truePositive: 0.6380 - falsePositive: 0.1746 - val_loss: 0.5279 - val_acc: 0.7348 - val_sigLoss: -587.6092 - val_significance: 24.5069 - val_asimovSignificance: 17.5874 - val_truePositive: 0.6458 - val_falsePositive: 0.1769\n",
      "Epoch 66/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5351 - acc: 0.7315 - sigLoss: -580.9129 - significance: 24.3700 - asimovSignificance: 17.5628 - truePositive: 0.6387 - falsePositive: 0.1755 - val_loss: 0.5282 - val_acc: 0.7347 - val_sigLoss: -587.0031 - val_significance: 24.4858 - val_asimovSignificance: 17.6122 - val_truePositive: 0.6446 - val_falsePositive: 0.1761\n",
      "Epoch 67/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5356 - acc: 0.7313 - sigLoss: -581.0122 - significance: 24.3682 - asimovSignificance: 17.5435 - truePositive: 0.6386 - falsePositive: 0.1756 - val_loss: 0.5280 - val_acc: 0.7348 - val_sigLoss: -581.9172 - val_significance: 24.4668 - val_asimovSignificance: 17.6601 - val_truePositive: 0.6435 - val_falsePositive: 0.1747\n",
      "Epoch 68/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5355 - acc: 0.7320 - sigLoss: -580.5478 - significance: 24.3990 - asimovSignificance: 17.5647 - truePositive: 0.6402 - falsePositive: 0.1759 - val_loss: 0.5279 - val_acc: 0.7349 - val_sigLoss: -583.6225 - val_significance: 24.4653 - val_asimovSignificance: 17.6695 - val_truePositive: 0.6435 - val_falsePositive: 0.1746\n",
      "Epoch 69/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5352 - acc: 0.7323 - sigLoss: -580.8663 - significance: 24.3909 - asimovSignificance: 17.5999 - truePositive: 0.6397 - falsePositive: 0.1749 - val_loss: 0.5280 - val_acc: 0.7346 - val_sigLoss: -584.8225 - val_significance: 24.3943 - val_asimovSignificance: 17.7768 - val_truePositive: 0.6396 - val_falsePositive: 0.1711\n",
      "Epoch 70/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5355 - acc: 0.7319 - sigLoss: -580.9032 - significance: 24.3834 - asimovSignificance: 17.5810 - truePositive: 0.6393 - falsePositive: 0.1752 - val_loss: 0.5281 - val_acc: 0.7346 - val_sigLoss: -584.0738 - val_significance: 24.4284 - val_asimovSignificance: 17.7072 - val_truePositive: 0.6415 - val_falsePositive: 0.1731\n",
      "Epoch 71/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5351 - acc: 0.7322 - sigLoss: -579.8493 - significance: 24.3473 - asimovSignificance: 17.6748 - truePositive: 0.6373 - falsePositive: 0.1726 - val_loss: 0.5279 - val_acc: 0.7349 - val_sigLoss: -587.2426 - val_significance: 24.5183 - val_asimovSignificance: 17.5774 - val_truePositive: 0.6464 - val_falsePositive: 0.1773\n",
      "Epoch 72/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5357 - acc: 0.7314 - sigLoss: -581.0073 - significance: 24.4024 - asimovSignificance: 17.5096 - truePositive: 0.6404 - falsePositive: 0.1773 - val_loss: 0.5282 - val_acc: 0.7348 - val_sigLoss: -584.4932 - val_significance: 24.4469 - val_asimovSignificance: 17.6992 - val_truePositive: 0.6424 - val_falsePositive: 0.1736\n",
      "Epoch 73/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5352 - acc: 0.7317 - sigLoss: -580.3837 - significance: 24.3737 - asimovSignificance: 17.5832 - truePositive: 0.6388 - falsePositive: 0.1751 - val_loss: 0.5279 - val_acc: 0.7346 - val_sigLoss: -586.2976 - val_significance: 24.4425 - val_asimovSignificance: 17.6865 - val_truePositive: 0.6422 - val_falsePositive: 0.1738\n",
      "Epoch 74/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5353 - acc: 0.7318 - sigLoss: -580.2134 - significance: 24.3779 - asimovSignificance: 17.5789 - truePositive: 0.6390 - falsePositive: 0.1752 - val_loss: 0.5279 - val_acc: 0.7348 - val_sigLoss: -588.1010 - val_significance: 24.4792 - val_asimovSignificance: 17.6333 - val_truePositive: 0.6442 - val_falsePositive: 0.1755\n",
      "Epoch 75/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5354 - acc: 0.7318 - sigLoss: -581.2223 - significance: 24.3784 - asimovSignificance: 17.5865 - truePositive: 0.6391 - falsePositive: 0.1752 - val_loss: 0.5281 - val_acc: 0.7351 - val_sigLoss: -587.0641 - val_significance: 24.5399 - val_asimovSignificance: 17.5535 - val_truePositive: 0.6476 - val_falsePositive: 0.1782\n",
      "Epoch 76/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5353 - acc: 0.7317 - sigLoss: -580.7713 - significance: 24.4014 - asimovSignificance: 17.5367 - truePositive: 0.6403 - falsePositive: 0.1766 - val_loss: 0.5282 - val_acc: 0.7349 - val_sigLoss: -587.2241 - val_significance: 24.5003 - val_asimovSignificance: 17.6119 - val_truePositive: 0.6454 - val_falsePositive: 0.1763\n",
      "Epoch 77/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5356 - acc: 0.7321 - sigLoss: -580.6756 - significance: 24.3945 - asimovSignificance: 17.5814 - truePositive: 0.6399 - falsePositive: 0.1755 - val_loss: 0.5279 - val_acc: 0.7350 - val_sigLoss: -584.7856 - val_significance: 24.4596 - val_asimovSignificance: 17.6973 - val_truePositive: 0.6431 - val_falsePositive: 0.1739\n",
      "Epoch 78/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5353 - acc: 0.7318 - sigLoss: -580.5931 - significance: 24.4024 - asimovSignificance: 17.5404 - truePositive: 0.6404 - falsePositive: 0.1764 - val_loss: 0.5280 - val_acc: 0.7349 - val_sigLoss: -587.7342 - val_significance: 24.5454 - val_asimovSignificance: 17.5302 - val_truePositive: 0.6479 - val_falsePositive: 0.1788\n",
      "Epoch 79/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5351 - acc: 0.7320 - sigLoss: -581.0375 - significance: 24.4245 - asimovSignificance: 17.5120 - truePositive: 0.6415 - falsePositive: 0.1773 - val_loss: 0.5279 - val_acc: 0.7348 - val_sigLoss: -585.1424 - val_significance: 24.4301 - val_asimovSignificance: 17.7273 - val_truePositive: 0.6415 - val_falsePositive: 0.1727\n",
      "Epoch 80/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5352 - acc: 0.7317 - sigLoss: -580.8548 - significance: 24.3539 - asimovSignificance: 17.6085 - truePositive: 0.6378 - falsePositive: 0.1740 - val_loss: 0.5282 - val_acc: 0.7349 - val_sigLoss: -586.6128 - val_significance: 24.5291 - val_asimovSignificance: 17.5528 - val_truePositive: 0.6470 - val_falsePositive: 0.1780\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5353 - acc: 0.7320 - sigLoss: -580.4276 - significance: 24.3713 - asimovSignificance: 17.6082 - truePositive: 0.6386 - falsePositive: 0.1744 - val_loss: 0.5282 - val_acc: 0.7345 - val_sigLoss: -589.3360 - val_significance: 24.4986 - val_asimovSignificance: 17.5731 - val_truePositive: 0.6454 - val_falsePositive: 0.1771\n",
      "Epoch 82/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5356 - acc: 0.7323 - sigLoss: -580.6665 - significance: 24.4112 - asimovSignificance: 17.5815 - truePositive: 0.6408 - falsePositive: 0.1759 - val_loss: 0.5280 - val_acc: 0.7345 - val_sigLoss: -588.2086 - val_significance: 24.5035 - val_asimovSignificance: 17.5671 - val_truePositive: 0.6456 - val_falsePositive: 0.1774\n",
      "Epoch 83/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5353 - acc: 0.7319 - sigLoss: -580.9085 - significance: 24.3626 - asimovSignificance: 17.6501 - truePositive: 0.6382 - falsePositive: 0.1740 - val_loss: 0.5280 - val_acc: 0.7351 - val_sigLoss: -587.2538 - val_significance: 24.5722 - val_asimovSignificance: 17.4995 - val_truePositive: 0.6494 - val_falsePositive: 0.1800\n",
      "Epoch 84/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5351 - acc: 0.7319 - sigLoss: -580.7213 - significance: 24.4010 - asimovSignificance: 17.5621 - truePositive: 0.6403 - falsePositive: 0.1760 - val_loss: 0.5280 - val_acc: 0.7348 - val_sigLoss: -586.9202 - val_significance: 24.5504 - val_asimovSignificance: 17.5076 - val_truePositive: 0.6482 - val_falsePositive: 0.1794\n",
      "Epoch 85/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5355 - acc: 0.7318 - sigLoss: -580.7897 - significance: 24.4086 - asimovSignificance: 17.5389 - truePositive: 0.6407 - falsePositive: 0.1767 - val_loss: 0.5280 - val_acc: 0.7348 - val_sigLoss: -586.4990 - val_significance: 24.4405 - val_asimovSignificance: 17.7126 - val_truePositive: 0.6421 - val_falsePositive: 0.1732\n",
      "Epoch 86/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5356 - acc: 0.7315 - sigLoss: -580.8699 - significance: 24.3775 - asimovSignificance: 17.5615 - truePositive: 0.6391 - falsePositive: 0.1756 - val_loss: 0.5279 - val_acc: 0.7349 - val_sigLoss: -585.5208 - val_significance: 24.4840 - val_asimovSignificance: 17.6398 - val_truePositive: 0.6445 - val_falsePositive: 0.1754\n",
      "Epoch 87/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5353 - acc: 0.7320 - sigLoss: -581.0123 - significance: 24.4019 - asimovSignificance: 17.5545 - truePositive: 0.6403 - falsePositive: 0.1760 - val_loss: 0.5280 - val_acc: 0.7350 - val_sigLoss: -582.4614 - val_significance: 24.4102 - val_asimovSignificance: 17.7896 - val_truePositive: 0.6404 - val_falsePositive: 0.1711\n",
      "Epoch 88/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5357 - acc: 0.7320 - sigLoss: -580.1443 - significance: 24.3570 - asimovSignificance: 17.6446 - truePositive: 0.6379 - falsePositive: 0.1735 - val_loss: 0.5280 - val_acc: 0.7349 - val_sigLoss: -585.0139 - val_significance: 24.4700 - val_asimovSignificance: 17.6660 - val_truePositive: 0.6437 - val_falsePositive: 0.1747\n",
      "Epoch 89/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5352 - acc: 0.7319 - sigLoss: -580.6610 - significance: 24.3735 - asimovSignificance: 17.5935 - truePositive: 0.6388 - falsePositive: 0.1746 - val_loss: 0.5278 - val_acc: 0.7344 - val_sigLoss: -584.2282 - val_significance: 24.4737 - val_asimovSignificance: 17.6040 - val_truePositive: 0.6440 - val_falsePositive: 0.1760\n",
      "Epoch 90/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5352 - acc: 0.7317 - sigLoss: -580.8197 - significance: 24.4069 - asimovSignificance: 17.5174 - truePositive: 0.6406 - falsePositive: 0.1769 - val_loss: 0.5280 - val_acc: 0.7349 - val_sigLoss: -585.3345 - val_significance: 24.4288 - val_asimovSignificance: 17.7392 - val_truePositive: 0.6414 - val_falsePositive: 0.1724\n",
      "Epoch 91/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5354 - acc: 0.7316 - sigLoss: -580.6904 - significance: 24.3684 - asimovSignificance: 17.5690 - truePositive: 0.6385 - falsePositive: 0.1751 - val_loss: 0.5279 - val_acc: 0.7350 - val_sigLoss: -583.8632 - val_significance: 24.4615 - val_asimovSignificance: 17.6922 - val_truePositive: 0.6432 - val_falsePositive: 0.1740\n",
      "Epoch 92/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5357 - acc: 0.7319 - sigLoss: -580.3001 - significance: 24.3745 - asimovSignificance: 17.6024 - truePositive: 0.6388 - falsePositive: 0.1747 - val_loss: 0.5281 - val_acc: 0.7347 - val_sigLoss: -588.0294 - val_significance: 24.5124 - val_asimovSignificance: 17.5669 - val_truePositive: 0.6461 - val_falsePositive: 0.1774\n",
      "Epoch 93/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5355 - acc: 0.7319 - sigLoss: -581.0685 - significance: 24.4057 - asimovSignificance: 17.5353 - truePositive: 0.6406 - falsePositive: 0.1765 - val_loss: 0.5279 - val_acc: 0.7347 - val_sigLoss: -585.3462 - val_significance: 24.4486 - val_asimovSignificance: 17.6838 - val_truePositive: 0.6426 - val_falsePositive: 0.1739\n",
      "Epoch 94/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5349 - acc: 0.7321 - sigLoss: -580.5522 - significance: 24.4097 - asimovSignificance: 17.5464 - truePositive: 0.6408 - falsePositive: 0.1764 - val_loss: 0.5281 - val_acc: 0.7347 - val_sigLoss: -588.5228 - val_significance: 24.4420 - val_asimovSignificance: 17.6916 - val_truePositive: 0.6422 - val_falsePositive: 0.1736\n",
      "Epoch 95/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5355 - acc: 0.7319 - sigLoss: -580.2759 - significance: 24.3641 - asimovSignificance: 17.6262 - truePositive: 0.6382 - falsePositive: 0.1740 - val_loss: 0.5279 - val_acc: 0.7345 - val_sigLoss: -587.3375 - val_significance: 24.4788 - val_asimovSignificance: 17.6107 - val_truePositive: 0.6443 - val_falsePositive: 0.1760\n",
      "Epoch 96/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5351 - acc: 0.7326 - sigLoss: -581.2533 - significance: 24.4035 - asimovSignificance: 17.6275 - truePositive: 0.6403 - falsePositive: 0.1746 - val_loss: 0.5282 - val_acc: 0.7346 - val_sigLoss: -587.9961 - val_significance: 24.4835 - val_asimovSignificance: 17.6097 - val_truePositive: 0.6445 - val_falsePositive: 0.1761\n",
      "Epoch 97/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5355 - acc: 0.7315 - sigLoss: -581.0353 - significance: 24.3901 - asimovSignificance: 17.5299 - truePositive: 0.6397 - falsePositive: 0.1764 - val_loss: 0.5280 - val_acc: 0.7351 - val_sigLoss: -585.6828 - val_significance: 24.4667 - val_asimovSignificance: 17.6879 - val_truePositive: 0.6435 - val_falsePositive: 0.1742\n",
      "Epoch 98/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5352 - acc: 0.7320 - sigLoss: -580.7109 - significance: 24.3824 - asimovSignificance: 17.5838 - truePositive: 0.6393 - falsePositive: 0.1750 - val_loss: 0.5280 - val_acc: 0.7349 - val_sigLoss: -586.6323 - val_significance: 24.4450 - val_asimovSignificance: 17.7157 - val_truePositive: 0.6423 - val_falsePositive: 0.1732\n",
      "Epoch 99/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5353 - acc: 0.7318 - sigLoss: -580.0924 - significance: 24.3691 - asimovSignificance: 17.5951 - truePositive: 0.6385 - falsePositive: 0.1747 - val_loss: 0.5281 - val_acc: 0.7350 - val_sigLoss: -589.7649 - val_significance: 24.4913 - val_asimovSignificance: 17.6357 - val_truePositive: 0.6449 - val_falsePositive: 0.1757\n",
      "Epoch 100/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5351 - acc: 0.7321 - sigLoss: -581.0751 - significance: 24.3872 - asimovSignificance: 17.6011 - truePositive: 0.6395 - falsePositive: 0.1749 - val_loss: 0.5281 - val_acc: 0.7349 - val_sigLoss: -588.6708 - val_significance: 24.5058 - val_asimovSignificance: 17.6016 - val_truePositive: 0.6457 - val_falsePositive: 0.1766\n",
      "Epoch 101/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5350 - acc: 0.7324 - sigLoss: -580.4494 - significance: 24.3681 - asimovSignificance: 17.6649 - truePositive: 0.6384 - falsePositive: 0.1732 - val_loss: 0.5283 - val_acc: 0.7346 - val_sigLoss: -589.2129 - val_significance: 24.6195 - val_asimovSignificance: 17.3708 - val_truePositive: 0.6521 - val_falsePositive: 0.1837\n",
      "Epoch 102/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5356 - acc: 0.7319 - sigLoss: -581.4551 - significance: 24.4249 - asimovSignificance: 17.4972 - truePositive: 0.6416 - falsePositive: 0.1776 - val_loss: 0.5280 - val_acc: 0.7348 - val_sigLoss: -583.8341 - val_significance: 24.4628 - val_asimovSignificance: 17.6732 - val_truePositive: 0.6433 - val_falsePositive: 0.1745\n",
      "Epoch 103/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5356 - acc: 0.7321 - sigLoss: -580.8281 - significance: 24.3983 - asimovSignificance: 17.5827 - truePositive: 0.6401 - falsePositive: 0.1756 - val_loss: 0.5281 - val_acc: 0.7349 - val_sigLoss: -586.6653 - val_significance: 24.5243 - val_asimovSignificance: 17.5671 - val_truePositive: 0.6467 - val_falsePositive: 0.1777\n",
      "Epoch 104/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5351 - acc: 0.7319 - sigLoss: -580.2165 - significance: 24.3894 - asimovSignificance: 17.5717 - truePositive: 0.6397 - falsePositive: 0.1755 - val_loss: 0.5280 - val_acc: 0.7349 - val_sigLoss: -588.9015 - val_significance: 24.5262 - val_asimovSignificance: 17.5628 - val_truePositive: 0.6468 - val_falsePositive: 0.1778\n",
      "Epoch 105/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5353 - acc: 0.7320 - sigLoss: -581.9603 - significance: 24.4072 - asimovSignificance: 17.5439 - truePositive: 0.6406 - falsePositive: 0.1765 - val_loss: 0.5279 - val_acc: 0.7348 - val_sigLoss: -584.5497 - val_significance: 24.4395 - val_asimovSignificance: 17.7065 - val_truePositive: 0.6421 - val_falsePositive: 0.1734\n",
      "Epoch 106/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5355 - acc: 0.7321 - sigLoss: -580.2595 - significance: 24.3869 - asimovSignificance: 17.5903 - truePositive: 0.6395 - falsePositive: 0.1750 - val_loss: 0.5279 - val_acc: 0.7349 - val_sigLoss: -584.6798 - val_significance: 24.5250 - val_asimovSignificance: 17.5697 - val_truePositive: 0.6468 - val_falsePositive: 0.1777\n",
      "Epoch 107/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5350 - acc: 0.7313 - sigLoss: -580.6889 - significance: 24.3868 - asimovSignificance: 17.5225 - truePositive: 0.6395 - falsePositive: 0.1765 - val_loss: 0.5279 - val_acc: 0.7351 - val_sigLoss: -586.2813 - val_significance: 24.4906 - val_asimovSignificance: 17.6491 - val_truePositive: 0.6448 - val_falsePositive: 0.1754\n",
      "Epoch 108/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5352 - acc: 0.7320 - sigLoss: -580.5025 - significance: 24.3636 - asimovSignificance: 17.6412 - truePositive: 0.6382 - falsePositive: 0.1738 - val_loss: 0.5279 - val_acc: 0.7353 - val_sigLoss: -588.8451 - val_significance: 24.5105 - val_asimovSignificance: 17.6277 - val_truePositive: 0.6459 - val_falsePositive: 0.1762\n",
      "Epoch 109/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5356 - acc: 0.7319 - sigLoss: -581.2692 - significance: 24.4043 - asimovSignificance: 17.5345 - truePositive: 0.6405 - falsePositive: 0.1764 - val_loss: 0.5279 - val_acc: 0.7348 - val_sigLoss: -583.5566 - val_significance: 24.4635 - val_asimovSignificance: 17.6650 - val_truePositive: 0.6434 - val_falsePositive: 0.1746\n",
      "Epoch 110/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5355 - acc: 0.7318 - sigLoss: -580.5589 - significance: 24.3643 - asimovSignificance: 17.6196 - truePositive: 0.6383 - falsePositive: 0.1743 - val_loss: 0.5279 - val_acc: 0.7350 - val_sigLoss: -582.7995 - val_significance: 24.4192 - val_asimovSignificance: 17.7660 - val_truePositive: 0.6409 - val_falsePositive: 0.1718\n",
      "Epoch 111/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5353 - acc: 0.7322 - sigLoss: -580.1867 - significance: 24.3701 - asimovSignificance: 17.6460 - truePositive: 0.6385 - falsePositive: 0.1737 - val_loss: 0.5278 - val_acc: 0.7348 - val_sigLoss: -584.9186 - val_significance: 24.5077 - val_asimovSignificance: 17.5833 - val_truePositive: 0.6458 - val_falsePositive: 0.1771\n",
      "Epoch 112/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5348 - acc: 0.7323 - sigLoss: -581.3379 - significance: 24.4329 - asimovSignificance: 17.5334 - truePositive: 0.6420 - falsePositive: 0.1770 - val_loss: 0.5280 - val_acc: 0.7346 - val_sigLoss: -586.7808 - val_significance: 24.4495 - val_asimovSignificance: 17.6768 - val_truePositive: 0.6426 - val_falsePositive: 0.1742\n",
      "Epoch 113/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5357 - acc: 0.7322 - sigLoss: -580.7783 - significance: 24.3929 - asimovSignificance: 17.6180 - truePositive: 0.6397 - falsePositive: 0.1749 - val_loss: 0.5279 - val_acc: 0.7346 - val_sigLoss: -585.1361 - val_significance: 24.4651 - val_asimovSignificance: 17.6418 - val_truePositive: 0.6435 - val_falsePositive: 0.1751\n",
      "Epoch 114/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5352 - acc: 0.7321 - sigLoss: -581.0257 - significance: 24.4109 - asimovSignificance: 17.5501 - truePositive: 0.6408 - falsePositive: 0.1763 - val_loss: 0.5279 - val_acc: 0.7346 - val_sigLoss: -586.5912 - val_significance: 24.5140 - val_asimovSignificance: 17.5580 - val_truePositive: 0.6462 - val_falsePositive: 0.1777\n",
      "Epoch 115/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5352 - acc: 0.7322 - sigLoss: -580.5307 - significance: 24.3768 - asimovSignificance: 17.6357 - truePositive: 0.6389 - falsePositive: 0.1740 - val_loss: 0.5278 - val_acc: 0.7348 - val_sigLoss: -584.0440 - val_significance: 24.5145 - val_asimovSignificance: 17.5741 - val_truePositive: 0.6462 - val_falsePositive: 0.1774\n",
      "Epoch 116/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5354 - acc: 0.7323 - sigLoss: -581.4595 - significance: 24.4512 - asimovSignificance: 17.4932 - truePositive: 0.6431 - falsePositive: 0.1783 - val_loss: 0.5279 - val_acc: 0.7347 - val_sigLoss: -584.8663 - val_significance: 24.4217 - val_asimovSignificance: 17.7376 - val_truePositive: 0.6411 - val_falsePositive: 0.1724\n",
      "Epoch 117/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5357 - acc: 0.7320 - sigLoss: -580.2179 - significance: 24.3806 - asimovSignificance: 17.5998 - truePositive: 0.6392 - falsePositive: 0.1747 - val_loss: 0.5279 - val_acc: 0.7347 - val_sigLoss: -583.6937 - val_significance: 24.4623 - val_asimovSignificance: 17.6579 - val_truePositive: 0.6433 - val_falsePositive: 0.1747\n",
      "Epoch 118/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5354 - acc: 0.7314 - sigLoss: -581.0356 - significance: 24.4098 - asimovSignificance: 17.5019 - truePositive: 0.6409 - falsePositive: 0.1776 - val_loss: 0.5279 - val_acc: 0.7348 - val_sigLoss: -582.6558 - val_significance: 24.3843 - val_asimovSignificance: 17.8168 - val_truePositive: 0.6390 - val_falsePositive: 0.1702\n",
      "Epoch 119/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5352 - acc: 0.7321 - sigLoss: -580.7219 - significance: 24.3444 - asimovSignificance: 17.6663 - truePositive: 0.6371 - falsePositive: 0.1728 - val_loss: 0.5279 - val_acc: 0.7345 - val_sigLoss: -584.5801 - val_significance: 24.4486 - val_asimovSignificance: 17.6638 - val_truePositive: 0.6426 - val_falsePositive: 0.1744\n",
      "Epoch 120/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5355 - acc: 0.7317 - sigLoss: -580.8588 - significance: 24.3960 - asimovSignificance: 17.5532 - truePositive: 0.6401 - falsePositive: 0.1762 - val_loss: 0.5278 - val_acc: 0.7349 - val_sigLoss: -585.4568 - val_significance: 24.4959 - val_asimovSignificance: 17.6144 - val_truePositive: 0.6452 - val_falsePositive: 0.1762\n",
      "Epoch 121/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5355 - acc: 0.7320 - sigLoss: -580.3378 - significance: 24.3757 - asimovSignificance: 17.6074 - truePositive: 0.6389 - falsePositive: 0.1745 - val_loss: 0.5280 - val_acc: 0.7346 - val_sigLoss: -584.1588 - val_significance: 24.5026 - val_asimovSignificance: 17.5760 - val_truePositive: 0.6456 - val_falsePositive: 0.1771\n",
      "Epoch 122/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5354 - acc: 0.7314 - sigLoss: -580.8708 - significance: 24.3986 - asimovSignificance: 17.5077 - truePositive: 0.6402 - falsePositive: 0.1771 - val_loss: 0.5280 - val_acc: 0.7345 - val_sigLoss: -582.5126 - val_significance: 24.4137 - val_asimovSignificance: 17.7311 - val_truePositive: 0.6406 - val_falsePositive: 0.1724\n",
      "Epoch 123/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5358 - acc: 0.7321 - sigLoss: -579.8162 - significance: 24.3545 - asimovSignificance: 17.6667 - truePositive: 0.6377 - falsePositive: 0.1732 - val_loss: 0.5279 - val_acc: 0.7348 - val_sigLoss: -586.2318 - val_significance: 24.4498 - val_asimovSignificance: 17.6883 - val_truePositive: 0.6426 - val_falsePositive: 0.1739\n",
      "Epoch 124/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5352 - acc: 0.7325 - sigLoss: -581.2116 - significance: 24.3964 - asimovSignificance: 17.6123 - truePositive: 0.6399 - falsePositive: 0.1746 - val_loss: 0.5278 - val_acc: 0.7348 - val_sigLoss: -585.8635 - val_significance: 24.5119 - val_asimovSignificance: 17.5739 - val_truePositive: 0.6461 - val_falsePositive: 0.1773\n",
      "Epoch 125/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5349 - acc: 0.7322 - sigLoss: -581.0558 - significance: 24.4052 - asimovSignificance: 17.5581 - truePositive: 0.6405 - falsePositive: 0.1759 - val_loss: 0.5279 - val_acc: 0.7349 - val_sigLoss: -585.0676 - val_significance: 24.4630 - val_asimovSignificance: 17.6814 - val_truePositive: 0.6433 - val_falsePositive: 0.1743\n",
      "Epoch 126/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5355 - acc: 0.7320 - sigLoss: -580.3170 - significance: 24.3751 - asimovSignificance: 17.6091 - truePositive: 0.6388 - falsePositive: 0.1745 - val_loss: 0.5278 - val_acc: 0.7347 - val_sigLoss: -585.0441 - val_significance: 24.4780 - val_asimovSignificance: 17.6313 - val_truePositive: 0.6442 - val_falsePositive: 0.1756\n",
      "Epoch 127/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5355 - acc: 0.7320 - sigLoss: -580.5253 - significance: 24.3805 - asimovSignificance: 17.5983 - truePositive: 0.6391 - falsePositive: 0.1747 - val_loss: 0.5281 - val_acc: 0.7348 - val_sigLoss: -587.2095 - val_significance: 24.5570 - val_asimovSignificance: 17.4985 - val_truePositive: 0.6486 - val_falsePositive: 0.1798\n",
      "Epoch 128/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5355 - acc: 0.7322 - sigLoss: -580.7477 - significance: 24.4011 - asimovSignificance: 17.5812 - truePositive: 0.6402 - falsePositive: 0.1756 - val_loss: 0.5280 - val_acc: 0.7344 - val_sigLoss: -586.5681 - val_significance: 24.5106 - val_asimovSignificance: 17.5393 - val_truePositive: 0.6461 - val_falsePositive: 0.1781\n",
      "Epoch 129/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5352 - acc: 0.7320 - sigLoss: -581.1034 - significance: 24.4080 - asimovSignificance: 17.5502 - truePositive: 0.6407 - falsePositive: 0.1764 - val_loss: 0.5279 - val_acc: 0.7346 - val_sigLoss: -586.0271 - val_significance: 24.5152 - val_asimovSignificance: 17.5561 - val_truePositive: 0.6463 - val_falsePositive: 0.1778\n",
      "Epoch 130/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5353 - acc: 0.7324 - sigLoss: -580.6632 - significance: 24.4061 - asimovSignificance: 17.5866 - truePositive: 0.6405 - falsePositive: 0.1754 - val_loss: 0.5283 - val_acc: 0.7347 - val_sigLoss: -589.4136 - val_significance: 24.5298 - val_asimovSignificance: 17.5331 - val_truePositive: 0.6471 - val_falsePositive: 0.1785\n",
      "Epoch 131/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5351 - acc: 0.7319 - sigLoss: -581.3183 - significance: 24.4009 - asimovSignificance: 17.5594 - truePositive: 0.6403 - falsePositive: 0.1762 - val_loss: 0.5280 - val_acc: 0.7350 - val_sigLoss: -586.3984 - val_significance: 24.5264 - val_asimovSignificance: 17.5718 - val_truePositive: 0.6468 - val_falsePositive: 0.1776\n",
      "Epoch 132/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5354 - acc: 0.7319 - sigLoss: -580.9972 - significance: 24.4045 - asimovSignificance: 17.5558 - truePositive: 0.6405 - falsePositive: 0.1764 - val_loss: 0.5278 - val_acc: 0.7349 - val_sigLoss: -582.3133 - val_significance: 24.4280 - val_asimovSignificance: 17.7467 - val_truePositive: 0.6414 - val_falsePositive: 0.1723\n",
      "Epoch 133/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5358 - acc: 0.7322 - sigLoss: -579.9013 - significance: 24.3971 - asimovSignificance: 17.6017 - truePositive: 0.6400 - falsePositive: 0.1754 - val_loss: 0.5280 - val_acc: 0.7348 - val_sigLoss: -586.5572 - val_significance: 24.5088 - val_asimovSignificance: 17.5821 - val_truePositive: 0.6459 - val_falsePositive: 0.1772\n",
      "Epoch 134/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5353 - acc: 0.7318 - sigLoss: -580.9357 - significance: 24.4156 - asimovSignificance: 17.5197 - truePositive: 0.6411 - falsePositive: 0.1770 - val_loss: 0.5278 - val_acc: 0.7348 - val_sigLoss: -586.8082 - val_significance: 24.5062 - val_asimovSignificance: 17.5930 - val_truePositive: 0.6457 - val_falsePositive: 0.1768\n",
      "Epoch 135/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5354 - acc: 0.7316 - sigLoss: -581.1365 - significance: 24.3761 - asimovSignificance: 17.5765 - truePositive: 0.6390 - falsePositive: 0.1754 - val_loss: 0.5279 - val_acc: 0.7346 - val_sigLoss: -585.5434 - val_significance: 24.4862 - val_asimovSignificance: 17.6070 - val_truePositive: 0.6447 - val_falsePositive: 0.1762\n",
      "Epoch 136/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5351 - acc: 0.7321 - sigLoss: -580.6830 - significance: 24.3963 - asimovSignificance: 17.5735 - truePositive: 0.6400 - falsePositive: 0.1755 - val_loss: 0.5281 - val_acc: 0.7345 - val_sigLoss: -586.9659 - val_significance: 24.5027 - val_asimovSignificance: 17.5688 - val_truePositive: 0.6456 - val_falsePositive: 0.1773\n",
      "Epoch 137/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5351 - acc: 0.7317 - sigLoss: -580.9376 - significance: 24.3857 - asimovSignificance: 17.5837 - truePositive: 0.6394 - falsePositive: 0.1755 - val_loss: 0.5278 - val_acc: 0.7348 - val_sigLoss: -586.1610 - val_significance: 24.4796 - val_asimovSignificance: 17.6336 - val_truePositive: 0.6443 - val_falsePositive: 0.1755\n",
      "Epoch 138/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5354 - acc: 0.7320 - sigLoss: -581.1967 - significance: 24.4124 - asimovSignificance: 17.5546 - truePositive: 0.6409 - falsePositive: 0.1765 - val_loss: 0.5279 - val_acc: 0.7350 - val_sigLoss: -586.1466 - val_significance: 24.4372 - val_asimovSignificance: 17.7352 - val_truePositive: 0.6419 - val_falsePositive: 0.1728\n",
      "Epoch 139/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5357 - acc: 0.7318 - sigLoss: -579.9849 - significance: 24.3818 - asimovSignificance: 17.5843 - truePositive: 0.6393 - falsePositive: 0.1752 - val_loss: 0.5278 - val_acc: 0.7349 - val_sigLoss: -584.0922 - val_significance: 24.4355 - val_asimovSignificance: 17.7340 - val_truePositive: 0.6418 - val_falsePositive: 0.1727\n",
      "Epoch 140/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5355 - acc: 0.7316 - sigLoss: -580.2001 - significance: 24.3886 - asimovSignificance: 17.5513 - truePositive: 0.6396 - falsePositive: 0.1760 - val_loss: 0.5281 - val_acc: 0.7347 - val_sigLoss: -588.8159 - val_significance: 24.5243 - val_asimovSignificance: 17.5499 - val_truePositive: 0.6468 - val_falsePositive: 0.1781\n",
      "Epoch 141/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5351 - acc: 0.7322 - sigLoss: -581.0264 - significance: 24.3760 - asimovSignificance: 17.6285 - truePositive: 0.6389 - falsePositive: 0.1742 - val_loss: 0.5279 - val_acc: 0.7351 - val_sigLoss: -585.0348 - val_significance: 24.4959 - val_asimovSignificance: 17.6318 - val_truePositive: 0.6451 - val_falsePositive: 0.1758\n",
      "Epoch 142/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5352 - acc: 0.7321 - sigLoss: -580.7405 - significance: 24.4178 - asimovSignificance: 17.5528 - truePositive: 0.6412 - falsePositive: 0.1764 - val_loss: 0.5280 - val_acc: 0.7347 - val_sigLoss: -587.3725 - val_significance: 24.5201 - val_asimovSignificance: 17.5518 - val_truePositive: 0.6465 - val_falsePositive: 0.1780\n",
      "Epoch 143/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5352 - acc: 0.7320 - sigLoss: -581.3259 - significance: 24.3847 - asimovSignificance: 17.5951 - truePositive: 0.6393 - falsePositive: 0.1750 - val_loss: 0.5278 - val_acc: 0.7349 - val_sigLoss: -584.8350 - val_significance: 24.5352 - val_asimovSignificance: 17.5491 - val_truePositive: 0.6473 - val_falsePositive: 0.1783\n",
      "Epoch 144/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5352 - acc: 0.7320 - sigLoss: -580.7900 - significance: 24.4027 - asimovSignificance: 17.5559 - truePositive: 0.6404 - falsePositive: 0.1761 - val_loss: 0.5279 - val_acc: 0.7349 - val_sigLoss: -582.3857 - val_significance: 24.4069 - val_asimovSignificance: 17.7782 - val_truePositive: 0.6402 - val_falsePositive: 0.1713\n",
      "Epoch 145/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5350 - acc: 0.7321 - sigLoss: -580.9784 - significance: 24.4134 - asimovSignificance: 17.5541 - truePositive: 0.6409 - falsePositive: 0.1766 - val_loss: 0.5279 - val_acc: 0.7350 - val_sigLoss: -585.3782 - val_significance: 24.4132 - val_asimovSignificance: 17.7825 - val_truePositive: 0.6406 - val_falsePositive: 0.1713\n",
      "Epoch 146/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5356 - acc: 0.7320 - sigLoss: -580.0335 - significance: 24.3546 - asimovSignificance: 17.6343 - truePositive: 0.6378 - falsePositive: 0.1736 - val_loss: 0.5278 - val_acc: 0.7349 - val_sigLoss: -585.4138 - val_significance: 24.4916 - val_asimovSignificance: 17.6263 - val_truePositive: 0.6449 - val_falsePositive: 0.1759\n",
      "Epoch 147/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5357 - acc: 0.7321 - sigLoss: -581.2133 - significance: 24.4119 - asimovSignificance: 17.5460 - truePositive: 0.6409 - falsePositive: 0.1765 - val_loss: 0.5279 - val_acc: 0.7348 - val_sigLoss: -586.1604 - val_significance: 24.4522 - val_asimovSignificance: 17.6848 - val_truePositive: 0.6427 - val_falsePositive: 0.1740\n",
      "Epoch 148/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5352 - acc: 0.7320 - sigLoss: -580.2790 - significance: 24.3796 - asimovSignificance: 17.6069 - truePositive: 0.6391 - falsePositive: 0.1748 - val_loss: 0.5278 - val_acc: 0.7348 - val_sigLoss: -586.5375 - val_significance: 24.4676 - val_asimovSignificance: 17.6652 - val_truePositive: 0.6436 - val_falsePositive: 0.1747\n",
      "Epoch 149/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5351 - acc: 0.7325 - sigLoss: -580.9640 - significance: 24.4020 - asimovSignificance: 17.6102 - truePositive: 0.6402 - falsePositive: 0.1750 - val_loss: 0.5283 - val_acc: 0.7348 - val_sigLoss: -588.3291 - val_significance: 24.4904 - val_asimovSignificance: 17.6224 - val_truePositive: 0.6449 - val_falsePositive: 0.1760\n",
      "Epoch 150/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5355 - acc: 0.7318 - sigLoss: -581.1065 - significance: 24.3981 - asimovSignificance: 17.5522 - truePositive: 0.6401 - falsePositive: 0.1763 - val_loss: 0.5281 - val_acc: 0.7350 - val_sigLoss: -586.9118 - val_significance: 24.4651 - val_asimovSignificance: 17.6824 - val_truePositive: 0.6434 - val_falsePositive: 0.1743\n",
      "Epoch 151/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5354 - acc: 0.7321 - sigLoss: -580.8027 - significance: 24.3632 - asimovSignificance: 17.6472 - truePositive: 0.6382 - falsePositive: 0.1735 - val_loss: 0.5278 - val_acc: 0.7346 - val_sigLoss: -584.8799 - val_significance: 24.4789 - val_asimovSignificance: 17.6162 - val_truePositive: 0.6443 - val_falsePositive: 0.1759\n",
      "Epoch 152/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5355 - acc: 0.7318 - sigLoss: -580.3478 - significance: 24.3710 - asimovSignificance: 17.6010 - truePositive: 0.6386 - falsePositive: 0.1747 - val_loss: 0.5278 - val_acc: 0.7349 - val_sigLoss: -581.1351 - val_significance: 24.4166 - val_asimovSignificance: 17.7684 - val_truePositive: 0.6407 - val_falsePositive: 0.1717\n",
      "Epoch 153/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5353 - acc: 0.7319 - sigLoss: -580.2094 - significance: 24.3601 - asimovSignificance: 17.6290 - truePositive: 0.6380 - falsePositive: 0.1740 - val_loss: 0.5280 - val_acc: 0.7346 - val_sigLoss: -590.0301 - val_significance: 24.5458 - val_asimovSignificance: 17.5016 - val_truePositive: 0.6480 - val_falsePositive: 0.1795\n",
      "Epoch 154/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5354 - acc: 0.7320 - sigLoss: -581.5836 - significance: 24.3890 - asimovSignificance: 17.5965 - truePositive: 0.6396 - falsePositive: 0.1753 - val_loss: 0.5280 - val_acc: 0.7349 - val_sigLoss: -584.5566 - val_significance: 24.4796 - val_asimovSignificance: 17.6452 - val_truePositive: 0.6443 - val_falsePositive: 0.1753\n",
      "Epoch 155/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5349 - acc: 0.7322 - sigLoss: -580.2983 - significance: 24.3873 - asimovSignificance: 17.6142 - truePositive: 0.6395 - falsePositive: 0.1748 - val_loss: 0.5279 - val_acc: 0.7346 - val_sigLoss: -587.7813 - val_significance: 24.5301 - val_asimovSignificance: 17.5294 - val_truePositive: 0.6471 - val_falsePositive: 0.1786\n",
      "Epoch 156/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5355 - acc: 0.7320 - sigLoss: -581.3649 - significance: 24.4085 - asimovSignificance: 17.5494 - truePositive: 0.6407 - falsePositive: 0.1763 - val_loss: 0.5280 - val_acc: 0.7349 - val_sigLoss: -585.6358 - val_significance: 24.4896 - val_asimovSignificance: 17.6344 - val_truePositive: 0.6448 - val_falsePositive: 0.1757\n",
      "Epoch 157/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5354 - acc: 0.7318 - sigLoss: -580.6490 - significance: 24.3627 - asimovSignificance: 17.6123 - truePositive: 0.6382 - falsePositive: 0.1743 - val_loss: 0.5279 - val_acc: 0.7348 - val_sigLoss: -586.0305 - val_significance: 24.4866 - val_asimovSignificance: 17.6204 - val_truePositive: 0.6447 - val_falsePositive: 0.1759\n",
      "Epoch 158/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5356 - acc: 0.7320 - sigLoss: -580.7543 - significance: 24.4100 - asimovSignificance: 17.5258 - truePositive: 0.6408 - falsePositive: 0.1766 - val_loss: 0.5281 - val_acc: 0.7347 - val_sigLoss: -586.9228 - val_significance: 24.4527 - val_asimovSignificance: 17.6726 - val_truePositive: 0.6428 - val_falsePositive: 0.1743\n",
      "Epoch 159/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5354 - acc: 0.7316 - sigLoss: -580.3543 - significance: 24.3410 - asimovSignificance: 17.6346 - truePositive: 0.6370 - falsePositive: 0.1735 - val_loss: 0.5280 - val_acc: 0.7345 - val_sigLoss: -585.8733 - val_significance: 24.5182 - val_asimovSignificance: 17.5388 - val_truePositive: 0.6465 - val_falsePositive: 0.1782\n",
      "Epoch 160/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5356 - acc: 0.7322 - sigLoss: -580.6000 - significance: 24.4037 - asimovSignificance: 17.5803 - truePositive: 0.6404 - falsePositive: 0.1758 - val_loss: 0.5281 - val_acc: 0.7348 - val_sigLoss: -585.2468 - val_significance: 24.4992 - val_asimovSignificance: 17.5977 - val_truePositive: 0.6454 - val_falsePositive: 0.1766\n",
      "Epoch 161/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5356 - acc: 0.7318 - sigLoss: -580.6595 - significance: 24.3876 - asimovSignificance: 17.5782 - truePositive: 0.6395 - falsePositive: 0.1754 - val_loss: 0.5278 - val_acc: 0.7349 - val_sigLoss: -583.0069 - val_significance: 24.4256 - val_asimovSignificance: 17.7478 - val_truePositive: 0.6413 - val_falsePositive: 0.1723\n",
      "Epoch 162/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5356 - acc: 0.7321 - sigLoss: -580.2668 - significance: 24.3924 - asimovSignificance: 17.5911 - truePositive: 0.6398 - falsePositive: 0.1754 - val_loss: 0.5279 - val_acc: 0.7346 - val_sigLoss: -585.5370 - val_significance: 24.4474 - val_asimovSignificance: 17.6784 - val_truePositive: 0.6425 - val_falsePositive: 0.1741\n",
      "Epoch 163/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5349 - acc: 0.7320 - sigLoss: -580.8459 - significance: 24.3696 - asimovSignificance: 17.6146 - truePositive: 0.6385 - falsePositive: 0.1741 - val_loss: 0.5279 - val_acc: 0.7350 - val_sigLoss: -584.5069 - val_significance: 24.4851 - val_asimovSignificance: 17.6409 - val_truePositive: 0.6446 - val_falsePositive: 0.1755\n",
      "Epoch 164/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5350 - acc: 0.7319 - sigLoss: -581.0937 - significance: 24.3943 - asimovSignificance: 17.5643 - truePositive: 0.6399 - falsePositive: 0.1758 - val_loss: 0.5280 - val_acc: 0.7348 - val_sigLoss: -585.8404 - val_significance: 24.4633 - val_asimovSignificance: 17.6713 - val_truePositive: 0.6434 - val_falsePositive: 0.1745\n",
      "Epoch 165/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5353 - acc: 0.7321 - sigLoss: -580.4292 - significance: 24.3702 - asimovSignificance: 17.6353 - truePositive: 0.6385 - falsePositive: 0.1740 - val_loss: 0.5279 - val_acc: 0.7347 - val_sigLoss: -585.8451 - val_significance: 24.5099 - val_asimovSignificance: 17.5733 - val_truePositive: 0.6460 - val_falsePositive: 0.1773\n",
      "Epoch 166/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5354 - acc: 0.7320 - sigLoss: -580.8393 - significance: 24.4153 - asimovSignificance: 17.5383 - truePositive: 0.6410 - falsePositive: 0.1767 - val_loss: 0.5282 - val_acc: 0.7347 - val_sigLoss: -589.8839 - val_significance: 24.5178 - val_asimovSignificance: 17.5616 - val_truePositive: 0.6464 - val_falsePositive: 0.1777\n",
      "Epoch 167/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5352 - acc: 0.7320 - sigLoss: -580.8843 - significance: 24.3723 - asimovSignificance: 17.6149 - truePositive: 0.6387 - falsePositive: 0.1744 - val_loss: 0.5282 - val_acc: 0.7348 - val_sigLoss: -588.7975 - val_significance: 24.5386 - val_asimovSignificance: 17.5350 - val_truePositive: 0.6475 - val_falsePositive: 0.1786\n",
      "Epoch 168/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5351 - acc: 0.7320 - sigLoss: -581.8858 - significance: 24.4365 - asimovSignificance: 17.5073 - truePositive: 0.6423 - falsePositive: 0.1779 - val_loss: 0.5282 - val_acc: 0.7347 - val_sigLoss: -585.7224 - val_significance: 24.4713 - val_asimovSignificance: 17.6363 - val_truePositive: 0.6438 - val_falsePositive: 0.1753\n",
      "Epoch 169/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5352 - acc: 0.7321 - sigLoss: -580.1079 - significance: 24.3659 - asimovSignificance: 17.6401 - truePositive: 0.6383 - falsePositive: 0.1736 - val_loss: 0.5280 - val_acc: 0.7348 - val_sigLoss: -586.1353 - val_significance: 24.4932 - val_asimovSignificance: 17.6098 - val_truePositive: 0.6450 - val_falsePositive: 0.1763\n",
      "Epoch 170/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5353 - acc: 0.7324 - sigLoss: -581.3226 - significance: 24.4035 - asimovSignificance: 17.6040 - truePositive: 0.6403 - falsePositive: 0.1752 - val_loss: 0.5278 - val_acc: 0.7350 - val_sigLoss: -585.6548 - val_significance: 24.4619 - val_asimovSignificance: 17.6858 - val_truePositive: 0.6433 - val_falsePositive: 0.1741\n",
      "Epoch 171/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5353 - acc: 0.7321 - sigLoss: -580.2045 - significance: 24.3648 - asimovSignificance: 17.6554 - truePositive: 0.6382 - falsePositive: 0.1736 - val_loss: 0.5279 - val_acc: 0.7348 - val_sigLoss: -585.7004 - val_significance: 24.4807 - val_asimovSignificance: 17.6345 - val_truePositive: 0.6443 - val_falsePositive: 0.1755\n",
      "Epoch 172/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5356 - acc: 0.7314 - sigLoss: -580.8791 - significance: 24.3875 - asimovSignificance: 17.5345 - truePositive: 0.6396 - falsePositive: 0.1765 - val_loss: 0.5284 - val_acc: 0.7348 - val_sigLoss: -588.3027 - val_significance: 24.4887 - val_asimovSignificance: 17.6175 - val_truePositive: 0.6448 - val_falsePositive: 0.1760\n",
      "Epoch 173/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5356 - acc: 0.7319 - sigLoss: -580.2541 - significance: 24.3568 - asimovSignificance: 17.6394 - truePositive: 0.6379 - falsePositive: 0.1737 - val_loss: 0.5279 - val_acc: 0.7350 - val_sigLoss: -587.3407 - val_significance: 24.4902 - val_asimovSignificance: 17.6407 - val_truePositive: 0.6448 - val_falsePositive: 0.1756\n",
      "Epoch 174/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5358 - acc: 0.7317 - sigLoss: -580.9278 - significance: 24.3874 - asimovSignificance: 17.5385 - truePositive: 0.6395 - falsePositive: 0.1759 - val_loss: 0.5281 - val_acc: 0.7352 - val_sigLoss: -585.1486 - val_significance: 24.4692 - val_asimovSignificance: 17.6976 - val_truePositive: 0.6436 - val_falsePositive: 0.1741\n",
      "Epoch 175/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5354 - acc: 0.7319 - sigLoss: -580.0137 - significance: 24.3485 - asimovSignificance: 17.6309 - truePositive: 0.6374 - falsePositive: 0.1733 - val_loss: 0.5280 - val_acc: 0.7348 - val_sigLoss: -587.2766 - val_significance: 24.5628 - val_asimovSignificance: 17.4875 - val_truePositive: 0.6489 - val_falsePositive: 0.1801\n",
      "Epoch 176/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5354 - acc: 0.7323 - sigLoss: -581.4900 - significance: 24.4236 - asimovSignificance: 17.5467 - truePositive: 0.6415 - falsePositive: 0.1765 - val_loss: 0.5280 - val_acc: 0.7348 - val_sigLoss: -585.1560 - val_significance: 24.4308 - val_asimovSignificance: 17.7283 - val_truePositive: 0.6416 - val_falsePositive: 0.1728\n",
      "Epoch 177/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5353 - acc: 0.7314 - sigLoss: -580.4883 - significance: 24.3451 - asimovSignificance: 17.6020 - truePositive: 0.6373 - falsePositive: 0.1740 - val_loss: 0.5280 - val_acc: 0.7346 - val_sigLoss: -586.1301 - val_significance: 24.5236 - val_asimovSignificance: 17.5433 - val_truePositive: 0.6467 - val_falsePositive: 0.1782\n",
      "Epoch 178/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5357 - acc: 0.7321 - sigLoss: -580.9802 - significance: 24.4071 - asimovSignificance: 17.5705 - truePositive: 0.6406 - falsePositive: 0.1760 - val_loss: 0.5280 - val_acc: 0.7346 - val_sigLoss: -586.6437 - val_significance: 24.5462 - val_asimovSignificance: 17.5009 - val_truePositive: 0.6480 - val_falsePositive: 0.1795\n",
      "Epoch 179/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5349 - acc: 0.7323 - sigLoss: -581.1257 - significance: 24.4023 - asimovSignificance: 17.6038 - truePositive: 0.6403 - falsePositive: 0.1753 - val_loss: 0.5281 - val_acc: 0.7348 - val_sigLoss: -587.7937 - val_significance: 24.4824 - val_asimovSignificance: 17.6266 - val_truePositive: 0.6444 - val_falsePositive: 0.1757\n",
      "Epoch 180/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5355 - acc: 0.7321 - sigLoss: -580.2080 - significance: 24.3646 - asimovSignificance: 17.6218 - truePositive: 0.6383 - falsePositive: 0.1739 - val_loss: 0.5279 - val_acc: 0.7348 - val_sigLoss: -587.9632 - val_significance: 24.4850 - val_asimovSignificance: 17.6270 - val_truePositive: 0.6446 - val_falsePositive: 0.1757\n",
      "Epoch 181/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5357 - acc: 0.7321 - sigLoss: -581.2424 - significance: 24.4018 - asimovSignificance: 17.5682 - truePositive: 0.6403 - falsePositive: 0.1758 - val_loss: 0.5281 - val_acc: 0.7348 - val_sigLoss: -585.0197 - val_significance: 24.4534 - val_asimovSignificance: 17.6869 - val_truePositive: 0.6428 - val_falsePositive: 0.1740\n",
      "Epoch 182/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5353 - acc: 0.7320 - sigLoss: -580.1146 - significance: 24.3431 - asimovSignificance: 17.6599 - truePositive: 0.6371 - falsePositive: 0.1728 - val_loss: 0.5280 - val_acc: 0.7345 - val_sigLoss: -588.1526 - val_significance: 24.5419 - val_asimovSignificance: 17.5015 - val_truePositive: 0.6478 - val_falsePositive: 0.1795\n",
      "Epoch 183/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5352 - acc: 0.7320 - sigLoss: -581.3681 - significance: 24.4097 - asimovSignificance: 17.5505 - truePositive: 0.6407 - falsePositive: 0.1765 - val_loss: 0.5279 - val_acc: 0.7346 - val_sigLoss: -585.2642 - val_significance: 24.4368 - val_asimovSignificance: 17.6970 - val_truePositive: 0.6419 - val_falsePositive: 0.1735\n",
      "Epoch 184/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5351 - acc: 0.7318 - sigLoss: -580.7013 - significance: 24.3442 - asimovSignificance: 17.6362 - truePositive: 0.6372 - falsePositive: 0.1732 - val_loss: 0.5278 - val_acc: 0.7352 - val_sigLoss: -582.9759 - val_significance: 24.4798 - val_asimovSignificance: 17.6734 - val_truePositive: 0.6442 - val_falsePositive: 0.1747\n",
      "Epoch 185/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5352 - acc: 0.7318 - sigLoss: -580.7160 - significance: 24.3901 - asimovSignificance: 17.5582 - truePositive: 0.6397 - falsePositive: 0.1758 - val_loss: 0.5280 - val_acc: 0.7349 - val_sigLoss: -586.8098 - val_significance: 24.4296 - val_asimovSignificance: 17.7357 - val_truePositive: 0.6415 - val_falsePositive: 0.1726\n",
      "Epoch 186/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5351 - acc: 0.7322 - sigLoss: -581.1513 - significance: 24.3833 - asimovSignificance: 17.6111 - truePositive: 0.6393 - falsePositive: 0.1744 - val_loss: 0.5279 - val_acc: 0.7351 - val_sigLoss: -585.2879 - val_significance: 24.4778 - val_asimovSignificance: 17.6695 - val_truePositive: 0.6441 - val_falsePositive: 0.1747\n",
      "Epoch 187/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5359 - acc: 0.7320 - sigLoss: -580.1848 - significance: 24.3846 - asimovSignificance: 17.5938 - truePositive: 0.6394 - falsePositive: 0.1750 - val_loss: 0.5280 - val_acc: 0.7351 - val_sigLoss: -585.7732 - val_significance: 24.4941 - val_asimovSignificance: 17.6406 - val_truePositive: 0.6450 - val_falsePositive: 0.1756\n",
      "Epoch 188/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5353 - acc: 0.7318 - sigLoss: -580.6726 - significance: 24.3598 - asimovSignificance: 17.6102 - truePositive: 0.6381 - falsePositive: 0.1742 - val_loss: 0.5279 - val_acc: 0.7348 - val_sigLoss: -586.0017 - val_significance: 24.5065 - val_asimovSignificance: 17.5855 - val_truePositive: 0.6458 - val_falsePositive: 0.1770\n",
      "Epoch 189/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5355 - acc: 0.7318 - sigLoss: -580.8523 - significance: 24.4072 - asimovSignificance: 17.5275 - truePositive: 0.6406 - falsePositive: 0.1767 - val_loss: 0.5279 - val_acc: 0.7348 - val_sigLoss: -585.7998 - val_significance: 24.4475 - val_asimovSignificance: 17.6931 - val_truePositive: 0.6425 - val_falsePositive: 0.1738\n",
      "Epoch 190/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5350 - acc: 0.7322 - sigLoss: -580.9193 - significance: 24.3977 - asimovSignificance: 17.5802 - truePositive: 0.6401 - falsePositive: 0.1754 - val_loss: 0.5280 - val_acc: 0.7352 - val_sigLoss: -588.3018 - val_significance: 24.4663 - val_asimovSignificance: 17.7038 - val_truePositive: 0.6435 - val_falsePositive: 0.1738\n",
      "Epoch 191/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5352 - acc: 0.7317 - sigLoss: -580.8862 - significance: 24.3574 - asimovSignificance: 17.6160 - truePositive: 0.6379 - falsePositive: 0.1740 - val_loss: 0.5279 - val_acc: 0.7347 - val_sigLoss: -585.9567 - val_significance: 24.5112 - val_asimovSignificance: 17.5719 - val_truePositive: 0.6460 - val_falsePositive: 0.1774\n",
      "Epoch 192/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5354 - acc: 0.7316 - sigLoss: -581.2974 - significance: 24.3949 - asimovSignificance: 17.5328 - truePositive: 0.6400 - falsePositive: 0.1764 - val_loss: 0.5282 - val_acc: 0.7347 - val_sigLoss: -586.7108 - val_significance: 24.4983 - val_asimovSignificance: 17.5971 - val_truePositive: 0.6453 - val_falsePositive: 0.1767\n",
      "Epoch 193/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5352 - acc: 0.7320 - sigLoss: -580.5414 - significance: 24.3609 - asimovSignificance: 17.6377 - truePositive: 0.6380 - falsePositive: 0.1736 - val_loss: 0.5280 - val_acc: 0.7349 - val_sigLoss: -584.0385 - val_significance: 24.4220 - val_asimovSignificance: 17.7571 - val_truePositive: 0.6410 - val_falsePositive: 0.1720\n",
      "Epoch 194/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5352 - acc: 0.7322 - sigLoss: -580.5933 - significance: 24.3556 - asimovSignificance: 17.6647 - truePositive: 0.6377 - falsePositive: 0.1730 - val_loss: 0.5278 - val_acc: 0.7351 - val_sigLoss: -584.3500 - val_significance: 24.4376 - val_asimovSignificance: 17.7475 - val_truePositive: 0.6419 - val_falsePositive: 0.1725\n",
      "Epoch 195/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5354 - acc: 0.7315 - sigLoss: -580.7891 - significance: 24.3627 - asimovSignificance: 17.5713 - truePositive: 0.6383 - falsePositive: 0.1751 - val_loss: 0.5280 - val_acc: 0.7347 - val_sigLoss: -583.4665 - val_significance: 24.4445 - val_asimovSignificance: 17.6946 - val_truePositive: 0.6423 - val_falsePositive: 0.1737\n",
      "Epoch 196/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5354 - acc: 0.7321 - sigLoss: -580.3484 - significance: 24.4045 - asimovSignificance: 17.5744 - truePositive: 0.6405 - falsePositive: 0.1761 - val_loss: 0.5281 - val_acc: 0.7351 - val_sigLoss: -588.5930 - val_significance: 24.4846 - val_asimovSignificance: 17.6598 - val_truePositive: 0.6445 - val_falsePositive: 0.1751\n",
      "Epoch 197/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5356 - acc: 0.7324 - sigLoss: -580.5967 - significance: 24.3807 - asimovSignificance: 17.6413 - truePositive: 0.6391 - falsePositive: 0.1740 - val_loss: 0.5279 - val_acc: 0.7347 - val_sigLoss: -588.1807 - val_significance: 24.4895 - val_asimovSignificance: 17.6135 - val_truePositive: 0.6448 - val_falsePositive: 0.1761\n",
      "Epoch 198/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5354 - acc: 0.7322 - sigLoss: -581.1370 - significance: 24.3798 - asimovSignificance: 17.6231 - truePositive: 0.6390 - falsePositive: 0.1742 - val_loss: 0.5278 - val_acc: 0.7346 - val_sigLoss: -585.3029 - val_significance: 24.4516 - val_asimovSignificance: 17.6739 - val_truePositive: 0.6427 - val_falsePositive: 0.1743\n",
      "Epoch 199/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5353 - acc: 0.7319 - sigLoss: -581.0089 - significance: 24.3997 - asimovSignificance: 17.5497 - truePositive: 0.6403 - falsePositive: 0.1762 - val_loss: 0.5279 - val_acc: 0.7348 - val_sigLoss: -586.1640 - val_significance: 24.4443 - val_asimovSignificance: 17.7001 - val_truePositive: 0.6423 - val_falsePositive: 0.1736\n",
      "Epoch 200/200\n",
      "140000/140000 [==============================] - 0s 3us/step - loss: 0.5353 - acc: 0.7318 - sigLoss: -580.7939 - significance: 24.3653 - asimovSignificance: 17.6111 - truePositive: 0.6383 - falsePositive: 0.1743 - val_loss: 0.5279 - val_acc: 0.7350 - val_sigLoss: -585.4789 - val_significance: 24.4902 - val_asimovSignificance: 17.6345 - val_truePositive: 0.6448 - val_falsePositive: 0.1757\n",
      "60000/60000 [==============================] - 0s 1us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felipe/hepML/MlClasses/Dnn.py:221: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  report = self.model.evaluate(X_test.as_matrix(), y_test.as_matrix(), sample_weight=weights_test, batch_size=batchSize)\n",
      "/home/felipe/hepML/MlClasses/Dnn.py:227: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  classificationReport(self.model.predict_classes(X_test.as_matrix()),self.model.predict(X_test.as_matrix()),y_test,f)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140000/140000 [==============================] - 0s 1us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felipe/hepML/MlClasses/Dnn.py:232: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  report = self.model.evaluate(X_train.as_matrix(), y_train.as_matrix(), sample_weight=weights_train, batch_size=batchSize)\n",
      "/home/felipe/hepML/MlClasses/Dnn.py:236: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  classificationReport(self.model.predict_classes(X_train.as_matrix()),self.model.predict(X_train.as_matrix()),y_train,f)\n",
      "/home/felipe/hepML/MlClasses/Dnn.py:254: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  rocCurve(self.model.predict(self.data.X_test.as_matrix()), self.data.y_test,self.output)\n",
      "/home/felipe/hepML/MlClasses/Dnn.py:255: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  rocCurve(self.model.predict(self.data.X_train.as_matrix()),self.data.y_train,self.output,append='_train')\n",
      "/home/felipe/hepML/MlClasses/Dnn.py:263: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  compareTrainTest(self.model.predict,self.data.X_train.as_matrix(),self.data.y_train.as_matrix(),\\\n",
      "/home/felipe/hepML/MlClasses/Dnn.py:264: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  self.data.X_test.as_matrix(),self.data.y_test.as_matrix(),self.output)\n",
      "/home/felipe/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/matplotlib/axes/_axes.py:6521: MatplotlibDeprecationWarning: \n",
      "The 'normed' kwarg was deprecated in Matplotlib 2.1 and will be removed in 3.1. Use 'density' instead.\n",
      "  alternative=\"'density'\", removal=\"3.1\")\n",
      "/home/felipe/hepML/MlClasses/PerformanceTests.py:79: VisibleDeprecationWarning: Passing `normed=True` on non-uniform bins has always been broken, and computes neither the probability density function nor the probability mass function. The result is only correct if the bins are uniform, when density=True will produce the same result anyway. The argument will be removed in a future version of numpy.\n",
      "  bins=bins, range=low_high, normed=True)\n",
      "/home/felipe/hepML/MlClasses/PerformanceTests.py:88: VisibleDeprecationWarning: Passing `normed=True` on non-uniform bins has always been broken, and computes neither the probability density function nor the probability mass function. The result is only correct if the bins are uniform, when density=True will produce the same result anyway. The argument will be removed in a future version of numpy.\n",
      "  bins=bins, range=low_high, normed=True)\n",
      "/home/felipe/hepML/MlClasses/Dnn.py:368: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  return self.model.predict(self.data.X_test.as_matrix())\n",
      "/home/felipe/hepML/MlClasses/Dnn.py:405: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  dataTest['truth']=self.data.y_test.as_matrix()\n"
     ]
    }
   ],
   "source": [
    "# I'm only running the DNN with binary cross entropy, letter I will include the other options.\n",
    "# so far it running perfect, I'm testing with their custom loss function.\n",
    "for varSetName,varSet in chosenVars.items():\n",
    "    #Pick out the expanded arrays\n",
    "    columnsInDataFrame = []\n",
    "    for k in combined.keys():\n",
    "        for v in varSet:\n",
    "            #Little trick to ensure only the start of the string is checked\n",
    "            if varSetName is '0L':\n",
    "                if ' '+v+' ' in ' '+k+' ': columnsInDataFrame.append(k)\n",
    "            elif ' '+v in ' '+k: columnsInDataFrame.append(k)\n",
    "\n",
    "\n",
    "    #Select just the features we're interested in\n",
    "    #For now setting NaNs to 0 for compatibility\n",
    "    combinedToRun = combined[columnsInDataFrame].copy()\n",
    "    combinedToRun.fillna(0,inplace=True)\n",
    "    \n",
    "    combinedToRun.index = np.arange(0,200000)\n",
    "    mlData = MlData(combinedToRun,'signal')\n",
    "\n",
    "    mlData.prepare(evalSize=0.0,testSize=0.3,limitSize=None)\n",
    "\n",
    "    for name,config in dnnConfigs.items():\n",
    "        dnn = Dnn(mlData,'testPlots/mlPlots/binary_crossentropy/bsmlike/'+varSetName+'/'+name)\n",
    "        dnn.setup(hiddenLayers=config['hiddenLayers'], dropOut=config['dropOut'],\n",
    "                  l2Regularization=config['l2Regularization'], optimizer=config['optimizer'],\n",
    "                  activation=config['activation'],\n",
    "                  loss='binary_crossentropy',\n",
    "                extraMetrics=[\n",
    "                    significanceLoss(expectedSignal,expectedBkgd),significanceFull(expectedSignal,expectedBkgd),\n",
    "                    asimovSignificanceFull(expectedSignal,expectedBkgd,systematic),truePositive,falsePositive\n",
    "                    ])\n",
    "        dnn.fit(epochs=config['epochs'],batch_size=config['batch_size'])\n",
    "        \n",
    "        dnn.explainPredictions()\n",
    "        dnn.diagnostics(batchSize=config['batch_size'])\n",
    "        dnn.makeHepPlots(expectedSignal,expectedBkgd,asimovSigLossSysts,makeHistograms=False)\n",
    "\n",
    "        trainedModels[varSetName+'_'+name]=dnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
